{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40da73afc2bc4afb846e6e57e3bcbd48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_757f0702b1104a018d25a90c38d4d97c",
              "IPY_MODEL_9180d5ecb8a14b6bbb803a5d109d2f25",
              "IPY_MODEL_fb0bc862866a4c65be81c42f0682d72d"
            ],
            "layout": "IPY_MODEL_8099bd77da3347bca6f1e99dfbe3f56d"
          }
        },
        "757f0702b1104a018d25a90c38d4d97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e2ef05655a343ad87f0a3089fc6134c",
            "placeholder": "​",
            "style": "IPY_MODEL_706192c00f9c48619f107e086dc60c68",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "9180d5ecb8a14b6bbb803a5d109d2f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_319c72ed57594ed4a4f56dc7922deb63",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6317fce05ca14a73ae4a03c4bda3c22e",
            "value": 231508
          }
        },
        "fb0bc862866a4c65be81c42f0682d72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4999398bcfe0483690baa0ba1c19c752",
            "placeholder": "​",
            "style": "IPY_MODEL_0ef6bcd9c51e4f6da69e77e62b6fd30a",
            "value": " 232k/232k [00:00&lt;00:00, 554kB/s]"
          }
        },
        "8099bd77da3347bca6f1e99dfbe3f56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e2ef05655a343ad87f0a3089fc6134c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "706192c00f9c48619f107e086dc60c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "319c72ed57594ed4a4f56dc7922deb63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6317fce05ca14a73ae4a03c4bda3c22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4999398bcfe0483690baa0ba1c19c752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef6bcd9c51e4f6da69e77e62b6fd30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e1e6ee034cc47e996cd85ccb2202ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7316889fb7642778d5c0b60513fb3aa",
              "IPY_MODEL_5b88b7f40892448ebfa7e9c5c3a71b5c",
              "IPY_MODEL_a79c15daa31d4c76acc24f42fcde945f"
            ],
            "layout": "IPY_MODEL_65b9d155850e4578926b50fc8388c042"
          }
        },
        "d7316889fb7642778d5c0b60513fb3aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e4d92c871a545d7aa676cda1b89a396",
            "placeholder": "​",
            "style": "IPY_MODEL_3a7c91dd727c409789d65957afab985f",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "5b88b7f40892448ebfa7e9c5c3a71b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f3a33cb5ca400884832e959d375760",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3894a2727539456f92a0ebed83c1bb60",
            "value": 28
          }
        },
        "a79c15daa31d4c76acc24f42fcde945f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f5ffd64be7a4fc29e39e33bc8a8ccee",
            "placeholder": "​",
            "style": "IPY_MODEL_f77e1585f5ef43b8a4477860d63e05b0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.57kB/s]"
          }
        },
        "65b9d155850e4578926b50fc8388c042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4d92c871a545d7aa676cda1b89a396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7c91dd727c409789d65957afab985f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76f3a33cb5ca400884832e959d375760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3894a2727539456f92a0ebed83c1bb60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f5ffd64be7a4fc29e39e33bc8a8ccee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77e1585f5ef43b8a4477860d63e05b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68bd3870749340bf95a98ec4f31b15c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_688b4a8868e04ada8309fb3d52f46e37",
              "IPY_MODEL_417e70c908c048a087e21e1d50281645",
              "IPY_MODEL_f034dd463ce54ab79a9a5c85f7c89098"
            ],
            "layout": "IPY_MODEL_85c76511d98e42e5969bdf6c9de14cbf"
          }
        },
        "688b4a8868e04ada8309fb3d52f46e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a15a80a3802430c81175b6d8a9df1d5",
            "placeholder": "​",
            "style": "IPY_MODEL_44d4f200610a4ae681d765add16c1441",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "417e70c908c048a087e21e1d50281645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cb1f4fdf2914755863257e3b481e72f",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16b593e87a154269acf16299866f68b9",
            "value": 570
          }
        },
        "f034dd463ce54ab79a9a5c85f7c89098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d48ab5ed0e46a7be7b561274cdb82d",
            "placeholder": "​",
            "style": "IPY_MODEL_ae37035d034e45feadeca692bfbac479",
            "value": " 570/570 [00:00&lt;00:00, 46.1kB/s]"
          }
        },
        "85c76511d98e42e5969bdf6c9de14cbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a15a80a3802430c81175b6d8a9df1d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d4f200610a4ae681d765add16c1441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cb1f4fdf2914755863257e3b481e72f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b593e87a154269acf16299866f68b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33d48ab5ed0e46a7be7b561274cdb82d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae37035d034e45feadeca692bfbac479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification\n",
        "\n",
        "\n",
        "## Dependencies"
      ],
      "metadata": {
        "id": "48L0_2GkAT6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import (\n",
        "    TensorDataset,\n",
        "    DataLoader,\n",
        "    RandomSampler,\n",
        "    SequentialSampler\n",
        ")\n",
        "\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQAwR6D-QTju",
        "outputId": "c6882341-fc58-4481-9d4e-b0be9238946e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.2-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.2 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "Fn0XGfdAQmH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl4Zdov_QWvc",
        "outputId": "bd23cb11-162a-4e20-b478-f8d23428a42b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-05 18:54:30--  https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘smsspamcollection.zip’\n",
            "\n",
            "smsspamcollection.z     [  <=>               ] 198.65K   408KB/s    in 0.5s    \n",
            "\n",
            "2023-07-05 18:54:31 (408 KB/s) - ‘smsspamcollection.zip’ saved [203415]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o smsspamcollection.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgwU_o7AQrmC",
        "outputId": "17429d2b-b623-449c-9685-26170438d0a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  smsspamcollection.zip\n",
            "  inflating: SMSSpamCollection       \n",
            "  inflating: readme                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/SMSSpamCollection'\n",
        "\n",
        "# Read file into a DataFrame directly\n",
        "df = pd.read_csv(file_path, sep='\\t', names=['label', 'text'])\n",
        "\n",
        "# Convert labels from 'spam'/'ham' to binary values\n",
        "df['label'] = df['label'].map({'spam': 1, 'ham': 0})\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CPNGkItmQwLL",
        "outputId": "cdd29cc4-463b-48fb-b91b-12469e473216"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd68a5fa-d420-47cb-86f8-27647c8f3831\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd68a5fa-d420-47cb-86f8-27647c8f3831')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd68a5fa-d420-47cb-86f8-27647c8f3831 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd68a5fa-d420-47cb-86f8-27647c8f3831');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = df.loc[:, \"text\"].values\n",
        "labels = df.loc[:, \"label\"].values\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPKlZhp-REIm",
        "outputId": "a13e051b-1656-4eca-8018-f0eb23c44e76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
            " 'Ok lar... Joking wif u oni...'\n",
            " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\n",
            " ... 'Pity, * was in mood for that. So...any other suggestions?'\n",
            " \"The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\"\n",
            " 'Rofl. Its true to its name']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "Sf25zx75RfMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    do_lower_case = True\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "40da73afc2bc4afb846e6e57e3bcbd48",
            "757f0702b1104a018d25a90c38d4d97c",
            "9180d5ecb8a14b6bbb803a5d109d2f25",
            "fb0bc862866a4c65be81c42f0682d72d",
            "8099bd77da3347bca6f1e99dfbe3f56d",
            "6e2ef05655a343ad87f0a3089fc6134c",
            "706192c00f9c48619f107e086dc60c68",
            "319c72ed57594ed4a4f56dc7922deb63",
            "6317fce05ca14a73ae4a03c4bda3c22e",
            "4999398bcfe0483690baa0ba1c19c752",
            "0ef6bcd9c51e4f6da69e77e62b6fd30a",
            "7e1e6ee034cc47e996cd85ccb2202ceb",
            "d7316889fb7642778d5c0b60513fb3aa",
            "5b88b7f40892448ebfa7e9c5c3a71b5c",
            "a79c15daa31d4c76acc24f42fcde945f",
            "65b9d155850e4578926b50fc8388c042",
            "9e4d92c871a545d7aa676cda1b89a396",
            "3a7c91dd727c409789d65957afab985f",
            "76f3a33cb5ca400884832e959d375760",
            "3894a2727539456f92a0ebed83c1bb60",
            "7f5ffd64be7a4fc29e39e33bc8a8ccee",
            "f77e1585f5ef43b8a4477860d63e05b0",
            "68bd3870749340bf95a98ec4f31b15c6",
            "688b4a8868e04ada8309fb3d52f46e37",
            "417e70c908c048a087e21e1d50281645",
            "f034dd463ce54ab79a9a5c85f7c89098",
            "85c76511d98e42e5969bdf6c9de14cbf",
            "9a15a80a3802430c81175b6d8a9df1d5",
            "44d4f200610a4ae681d765add16c1441",
            "3cb1f4fdf2914755863257e3b481e72f",
            "16b593e87a154269acf16299866f68b9",
            "33d48ab5ed0e46a7be7b561274cdb82d",
            "ae37035d034e45feadeca692bfbac479"
          ]
        },
        "id": "GqGcHjlXRQri",
        "outputId": "af4015f5-8f42-4738-a12a-565e4eba6229"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40da73afc2bc4afb846e6e57e3bcbd48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e1e6ee034cc47e996cd85ccb2202ceb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68bd3870749340bf95a98ec4f31b15c6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_rand_sentence():\n",
        "  '''Displays the tokens and respective IDs of a random text sample'''\n",
        "  selected_text = random.choice(text)\n",
        "  tokens = tokenizer.tokenize(selected_text)\n",
        "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  table = list(zip(tokens, token_ids))\n",
        "  print(tabulate(table, headers = ['Tokens', 'Token IDs'], tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naHp39sORlF0",
        "outputId": "3f0061f0-4643-45ba-a316-2b80969e0834"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒══════════╤═════════════╕\n",
            "│ Tokens   │   Token IDs │\n",
            "╞══════════╪═════════════╡\n",
            "│ yu       │        9805 │\n",
            "├──────────┼─────────────┤\n",
            "│ ##p      │        2361 │\n",
            "├──────────┼─────────────┤\n",
            "│ .        │        1012 │\n",
            "├──────────┼─────────────┤\n",
            "│ .        │        1012 │\n",
            "├──────────┼─────────────┤\n",
            "│ .        │        1012 │\n",
            "├──────────┼─────────────┤\n",
            "│ hey      │        4931 │\n",
            "├──────────┼─────────────┤\n",
            "│ then     │        2059 │\n",
            "├──────────┼─────────────┤\n",
            "│ one      │        2028 │\n",
            "├──────────┼─────────────┤\n",
            "│ day      │        2154 │\n",
            "├──────────┼─────────────┤\n",
            "│ on       │        2006 │\n",
            "├──────────┼─────────────┤\n",
            "│ fr       │       10424 │\n",
            "├──────────┼─────────────┤\n",
            "│ ##i      │        2072 │\n",
            "├──────────┼─────────────┤\n",
            "│ we       │        2057 │\n",
            "├──────────┼─────────────┤\n",
            "│ can      │        2064 │\n",
            "├──────────┼─────────────┤\n",
            "│ ask      │        3198 │\n",
            "├──────────┼─────────────┤\n",
            "│ mi       │        2771 │\n",
            "├──────────┼─────────────┤\n",
            "│ ##wa     │        4213 │\n",
            "├──────────┼─────────────┤\n",
            "│ and      │        1998 │\n",
            "├──────────┼─────────────┤\n",
            "│ jia      │       25871 │\n",
            "├──────────┼─────────────┤\n",
            "│ ##yin    │       25811 │\n",
            "├──────────┼─────────────┤\n",
            "│ take     │        2202 │\n",
            "├──────────┼─────────────┤\n",
            "│ leave    │        2681 │\n",
            "├──────────┼─────────────┤\n",
            "│ go       │        2175 │\n",
            "├──────────┼─────────────┤\n",
            "│ kara     │       13173 │\n",
            "├──────────┼─────────────┤\n",
            "│ ##oke    │       11045 │\n",
            "╘══════════╧═════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(input_text, tokenizer):\n",
        "    preprocess = tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 32,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "    return preprocess\n",
        "\n",
        "\n",
        "\n",
        "token_id, attention_masks = [], []\n",
        "\n",
        "for sample in text:\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  token_id.append(encoding_dict['input_ids'])\n",
        "  attention_masks.append(encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "token_id = torch.cat(token_id, dim = 0)\n",
        "attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXxP6g4-R3_2",
        "outputId": "2390a4f4-0139-4934-fe04-4fa39309c362"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(token_id[np.random.randint(0, len(token_id)-1)]) # 101 = CLS; 102 = SEP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7KTSSMGSZU8",
        "outputId": "cac5965f-b60f-4e27-be78-7eee3891bbcb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  101,  2196,  7499,  1037,  2154,  1999, 24471,  2166,  1012,  2204,\n",
            "         2420,  2507,  1057,  8404,  1012,  2919,  2420,  2507,  1057,  3325,\n",
            "         1012,  2119,  2024,  6827,  1999,  2166,   999,  2035,  2024,  5932,\n",
            "        24618,   102])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_rand_sentence_encoding():\n",
        "    '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
        "    index = random.randint(0, len(text) - 1)\n",
        "\n",
        "    tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
        "    token_ids = token_id[index].tolist()\n",
        "    attention = attention_masks[index].tolist()\n",
        "\n",
        "    table = list(zip(tokens, token_id, attention))\n",
        "    print(tabulate(table,\n",
        "                   headers=['Tokens', 'Token IDs', 'Attention Mask'],\n",
        "                   tablefmt='fancy_grid'))\n",
        "\n",
        "print_rand_sentence_encoding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBXDVStzSxYf",
        "outputId": "7cff2621-6b70-4ab2-b76f-c46a33412cc1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒══════════╤═════════════════════════════════════════════════════════════════════════════════╤══════════════════╕\n",
            "│ Tokens   │ Token IDs                                                                       │   Attention Mask │\n",
            "╞══════════╪═════════════════════════════════════════════════════════════════════════════════╪══════════════════╡\n",
            "│ [CLS]    │ tensor([  101,  2175,  2127, 18414, 17583,  2391,  1010,  4689,  1012,  1012,   │                1 │\n",
            "│          │          2800,  2069,  1999, 11829,  2483,  1050,  2307,  2088,  2474,  1041,   │                  │\n",
            "│          │         28305,  1012,  1012,  1012, 25022,  2638,  2045,  2288, 26297, 28194,   │                  │\n",
            "│          │          1012,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ lo       │ tensor([  101,  7929,  2474,  2099,  1012,  1012,  1012, 16644, 15536,  2546,   │                1 │\n",
            "│          │          1057,  2006,  2072,  1012,  1012,  1012,   102,     0,     0,     0,   │                  │\n",
            "│          │             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,   │                  │\n",
            "│          │             0,     0])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ ##l      │ tensor([  101,  2489,  4443,  1999,  1016,  1037,  1059,  2243,  2135,  4012,   │                1 │\n",
            "│          │          2361,  2000,  2663,  6904,  2452,  2345,  1056, 25509,  2015,  7398,   │                  │\n",
            "│          │          2089,  2384,  1012,  3793,  6904,  2000,  6584, 12521,  2487,  2000,   │                  │\n",
            "│          │          4374,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ ,        │ tensor([  101,  1057, 24654,  2360,  2061,  2220,  7570,  2099,  1012,  1012,   │                1 │\n",
            "│          │          1012,  1057,  1039,  2525,  2059,  2360,  1012,  1012,  1012,   102,   │                  │\n",
            "│          │             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,   │                  │\n",
            "│          │             0,     0])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ oh       │ tensor([  101, 20976,  1045,  2123,  1005,  1056,  2228,  2002,  3632,  2000,   │                1 │\n",
            "│          │          2149,  2546,  1010,  2002,  3268,  2105,  2182,  2295,   102,     0,   │                  │\n",
            "│          │             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,   │                  │\n",
            "│          │             0,     0])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ you      │ tensor([ 101, 2489, 5244, 2290, 4931, 2045, 9548, 2009, 1005, 1055, 2042, 1017, │                1 │\n",
            "│          │         2733, 1005, 1055, 2085, 1998, 2053, 2773, 2067,  999, 1045, 1005, 1040, │                  │\n",
            "│          │         2066, 2070, 4569, 2017, 2039, 2005, 2009,  102])                        │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ got      │ tensor([ 101, 2130, 2026, 2567, 2003, 2025, 2066, 2000, 3713, 2007, 2033, 1012, │                1 │\n",
            "│          │         2027, 7438, 2033, 2066, 8387, 7353, 1012,  102,    0,    0,    0,    0, │                  │\n",
            "│          │            0,    0,    0,    0,    0,    0,    0,    0])                        │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ a        │ tensor([  101,  2004,  2566,  2115,  5227,  1005, 11463,  2571, 11463,  2571,   │                1 │\n",
            "│          │          1006,  2030,  2226,  8117, 28987, 11231,  3070, 18447,  2063, 27617,   │                  │\n",
            "│          │          5575,  2226, 29525, 15464,  1007,  1005,  2038,  2042,  2275,  2004,   │                  │\n",
            "│          │          2115,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ friend   │ tensor([  101,  3453,   999,   999,  2004,  1037, 11126,  2897,  8013,  2017,   │                1 │\n",
            "│          │          2031,  2042,  3479,  2000,  4374,  2050,  1069, 21057,  2692,  3396,   │                  │\n",
            "│          │         10377,   999,  2000,  4366,  2655,  5641,  2692,  2575, 16576, 24096,   │                  │\n",
            "│          │         21472,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ for      │ tensor([  101,  2018,  2115,  4684,  2340,  2706,  2030,  2062,  1029,  1057,   │                1 │\n",
            "│          │          1054,  4709,  2000, 10651,  2000,  1996,  6745,  6120,  4684,  2015,   │                  │\n",
            "│          │          2007,  4950,  2005,  2489,   999,  2655,  1996,  4684, 10651,  2522,   │                  │\n",
            "│          │          2489,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ the      │ tensor([ 101, 1045, 1005, 1049, 6069, 2022, 2188, 2574, 1998, 1045, 2123, 1005, │                1 │\n",
            "│          │         1056, 2215, 2000, 2831, 2055, 2023, 4933, 4902, 3892, 1010, 1047, 1029, │                  │\n",
            "│          │         1045, 1005, 2310, 6639, 2438, 2651, 1012,  102])                        │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ dog      │ tensor([  101,  2416,  9592,  2000,  2663,  5356,   999,  2013,  2531,  2000,   │                1 │\n",
            "│          │          2322,  1010,  2199,  7038, 19067,  2102,  1028, 20116,  2232, 14526,   │                  │\n",
            "│          │          1998,  4604,  2000, 27658, 23352,  1012,  3465,  5018,  2361,  1013,   │                  │\n",
            "│          │          2154,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ ?        │ tensor([  101, 13661,   999,  2017,  2031,  2180,  1037,  1015,  2733,  2489,   │                1 │\n",
            "│          │          5779,  1999,  2256, 27708,  1010,  2199,  3396,  2990, 11008,   999,   │                  │\n",
            "│          │         19067,  2102,  1996,  2773,  1024,  4366,  2000,  2053,  1024,  6282,   │                  │\n",
            "│          │         24096,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [SEP]    │ tensor([  101,  1045,  1005,  2310,  2042,  6575,  2005,  1996,  2157,  2616,   │                1 │\n",
            "│          │          2000,  4067,  2017,  2005,  2023,  7200,  2099,  1012,  1045,  4872,   │                  │\n",
            "│          │          1045,  2180,  2102,  2202,  2115,  2393,  2005,  4379,  1998,  2097,   │                  │\n",
            "│          │         11865,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([ 101, 1045, 2031, 1037, 3058, 2006, 4465, 2007, 2097,  999,  999,  102, │                0 │\n",
            "│          │            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, │                  │\n",
            "│          │            0,    0,    0,    0,    0,    0,    0,    0])                        │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101, 22038,  2595, 17751,  5302, 13469, 20464, 12083,  1024,  2000,   │                0 │\n",
            "│          │          2224,  2115,  4923,  1010, 11562,  1996, 11333,  2361,  4957,  1999,   │                  │\n",
            "│          │          1996,  2279, 19067,  2102,  4471,  2030, 11562,  2182,  1028,  1028,   │                  │\n",
            "│          │          8299,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([ 101, 2821, 1047, 1012, 1012, 1012, 1045, 1005, 1049, 3666, 2182, 1024, │                0 │\n",
            "│          │         1007,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, │                  │\n",
            "│          │            0,    0,    0,    0,    0,    0,    0,    0])                        │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101, 15501,  1057,  3342,  2129,  1016,  6297,  2010,  2171,  1012,   │                0 │\n",
            "│          │          1012,  1012,  2748,  1045,  2106,  1012,  2002,  1058, 20355,  2191,   │                  │\n",
            "│          │          2127,  1045,  1058,  4954,  1012,   102,     0,     0,     0,     0,   │                  │\n",
            "│          │             0,     0])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([ 101, 2986, 2065, 2008, 2015, 1996, 2126, 1057, 2514, 1012, 2008, 2015, │                0 │\n",
            "│          │         1996, 2126, 2049, 2288, 2050, 1038,  102,    0,    0,    0,    0,    0, │                  │\n",
            "│          │            0,    0,    0,    0,    0,    0,    0,    0])                        │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101,  2563,  1058, 11492,  1011,  2123,  2102,  3335,  1996,  3289,   │                0 │\n",
            "│          │          1013,  2136,  2739,  1012, 19067,  2102, 24471,  2120,  2136,  2000,   │                  │\n",
            "│          │         28864,  2581,  2581,  1041,  2290,  2563,  2000, 28864,  2581,  2581,   │                  │\n",
            "│          │          3046,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([ 101, 2003, 2008, 5667, 2129, 2017, 6297, 2010, 2171, 1029,  102,    0, │                0 │\n",
            "│          │            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, │                  │\n",
            "│          │            0,    0,    0,    0,    0,    0,    0,    0])                        │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101,  1045,  1520,  1049,  2183,  2000,  3046,  2005,  1016,  2706,   │                0 │\n",
            "│          │          5292,  5292,  2069, 16644,   102,     0,     0,     0,     0,     0,   │                  │\n",
            "│          │             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,   │                  │\n",
            "│          │             0,     0])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([ 101, 2061, 1057, 3477, 2034, 2474, 2099, 1012, 1012, 1012, 2059, 2043, │                0 │\n",
            "│          │         2003, 4830, 4518, 4012, 2378, 1012, 1012, 1012,  102,    0,    0,    0, │                  │\n",
            "│          │            0,    0,    0,    0,    0,    0,    0,    0])                        │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101, 16638,  1045,  3926,  2026,  6265,  2059,  1045,  2175,  2358,   │                0 │\n",
            "│          │          2099,  2091,  8840,  2099,  1012, 12098,  2094,  1017, 15488,  2705,   │                  │\n",
            "│          │          8840,  2099,  1012,  1057,  3926, 24471,  6265,  2525,  1029,   102,   │                  │\n",
            "│          │             0,     0])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101, 21461,  4246,  4246,  4246,  4246,  1012, 10303,  2053,  2126,   │                0 │\n",
            "│          │          1045,  2064,  3113,  2039,  2007,  2017, 10076,  1029,   102,     0,   │                  │\n",
            "│          │             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,   │                  │\n",
            "│          │             0,     0])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101,  2074,  3140,  2870,  2000,  4521,  1037, 14704,  1012,  1045,   │                0 │\n",
            "│          │          1005,  1049,  2428,  2025,  7501, 27793,  1012,  2023, 19237,  1012,   │                  │\n",
            "│          │          2928,  2003,  2893,  5191,  1012,  2002,  4282,  1045,  1005,  1049,   │                  │\n",
            "│          │          5305,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101,  8840,  2140,  2115,  2467,  2061, 13359,  1012,   102,     0,   │                0 │\n",
            "│          │             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,   │                  │\n",
            "│          │             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,   │                  │\n",
            "│          │             0,     0])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101,  2106,  2017,  4608,  1996,  3902,  1029,  2024,  2017, 14744,   │                0 │\n",
            "│          │          2075,  2019,  8288,  1029,  2106,  2017,  2191,  1037,  5572,  1029,   │                  │\n",
            "│          │          2024,  2017,  5983,  2115,  3566,  1005,  1055,  2187,  2058,  4596,   │                  │\n",
            "│          │          1029,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101,  1045,  1005,  1049,  2067,  1004, 23713,  1025,  2057,  1005,   │                0 │\n",
            "│          │          2128, 14743,  1996,  2482,  2085,  1010,  1045,  1005,  2222,  2292,   │                  │\n",
            "│          │          2017,  2113,  2065,  2045,  1005,  1055,  2282,   102,     0,     0,   │                  │\n",
            "│          │             0,     0])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101,  6289, 23644,  1012,  2147,  1012,  1045, 15221,  3342,  2008,   │                0 │\n",
            "│          │           999,  2054,  2515,  2009,  2514,  2066,  1029,  8840,  2140,   102,   │                  │\n",
            "│          │             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,   │                  │\n",
            "│          │             0,     0])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101,  3524,  2008,  1005,  1055,  2145,  2025,  2035,  2008,  3154,   │                0 │\n",
            "│          │          1010,  2020,  2017,  2025,  2469,  2055,  2033,  2108, 22473,  2030,   │                  │\n",
            "│          │          2008,  2008,  1005,  1055,  2339,  1060,  2987,  1005,  1056,  2215,   │                  │\n",
            "│          │          2000,   102])                                                          │                  │\n",
            "├──────────┼─────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
            "│ [PAD]    │ tensor([  101,  3398,  2002,  2288,  1999,  2012,  1016,  1998,  2001,  1058,   │                0 │\n",
            "│          │         29352,  1012,  1050,  2018,  5357,  2041,  1998,  2016,  2001,  2552,   │                  │\n",
            "│          │          2378,  2066, 27594,  2102,  2775,  1998,  2002,  2288,  3236,  2039,   │                  │\n",
            "│          │          1999,   102])                                                          │                  │\n",
            "╘══════════╧═════════════════════════════════════════════════════════════════════════════════╧══════════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data split"
      ],
      "metadata": {
        "id": "n2PW75yCUuNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(features, masks, labels, indices, batch_size):\n",
        "    \"\"\"Create DataLoader from given features, masks, and labels.\"\"\"\n",
        "    dataset = TensorDataset(features[indices], masks[indices], labels[indices])\n",
        "    if indices[0] == 0:  # Training set, use RandomSampler\n",
        "        sampler = RandomSampler(dataset)\n",
        "    else:  # Validation set, use SequentialSampler\n",
        "        sampler = SequentialSampler(dataset)\n",
        "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "val_ratio = 0.2\n",
        "batch_size = 16  # Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "\n",
        "# Indices of the train and validation splits stratified by labels\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(labels)),\n",
        "    test_size=val_ratio,\n",
        "    shuffle=True,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "# Train and validation DataLoaders\n",
        "train_dataloader = create_dataloader(token_id, attention_masks, labels, train_idx, batch_size)\n",
        "validation_dataloader = create_dataloader(token_id, attention_masks, labels, val_idx, batch_size)\n"
      ],
      "metadata": {
        "id": "-NnId0QHTf9q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader size: \", len(train_dataloader))\n",
        "print(\"Validation loader size: \", len(validation_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwRQ3NvVU8g7",
        "outputId": "ffa7bed2-e630-4437-d43f-3345418513f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader size:  279\n",
            "Validation loader size:  70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Metrics"
      ],
      "metadata": {
        "id": "9nIuM5nYVicE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def b_tp(preds, labels):\n",
        "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
        "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fp(preds, labels):\n",
        "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
        "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_tn(preds, labels):\n",
        "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
        "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fn(preds, labels):\n",
        "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
        "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_metrics(preds, labels):\n",
        "  '''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "  '''\n",
        "  preds = np.argmax(preds, axis = 1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  tp = b_tp(preds, labels)\n",
        "  tn = b_tn(preds, labels)\n",
        "  fp = b_fp(preds, labels)\n",
        "  fn = b_fn(preds, labels)\n",
        "  b_accuracy = (tp + tn) / len(labels)\n",
        "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
        "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
        "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
        "  return b_accuracy, b_precision, b_recall, b_specificity\n"
      ],
      "metadata": {
        "id": "koJIHqPKVHzD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                              lr = 5e-5,\n",
        "                              eps = 1e-08\n",
        "                              )\n",
        "\n",
        "# Run on GPU\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TAk6aRzWJaH",
        "outputId": "bc7a5ff6-02ac-445c-d19b-b5a5103f13dc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "epochs = 2\n",
        "\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "\n",
        "    # ========== Training ==========\n",
        "\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids,\n",
        "                             token_type_ids = None,\n",
        "                             attention_mask = b_input_mask,\n",
        "                             labels = b_labels)\n",
        "        # Backward pass\n",
        "        train_output.loss.backward()\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += train_output.loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids,\n",
        "                              token_type_ids = None,\n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN262MxoWT5T",
        "outputId": "112f3416-8b1d-4da6-d4c2-a007ad9244c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  50%|█████     | 1/2 [00:36<00:36, 36.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.0758\n",
            "\t - Validation Accuracy: 0.9902\n",
            "\t - Validation Precision: 0.9957\n",
            "\t - Validation Recall: 0.9278\n",
            "\t - Validation Specificity: 0.9989\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 2/2 [01:11<00:00, 35.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.0283\n",
            "\t - Validation Accuracy: 0.9857\n",
            "\t - Validation Precision: 0.9693\n",
            "\t - Validation Recall: 0.9097\n",
            "\t - Validation Specificity: 0.9948\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = new_text = \"Congratulations! As our loyal customer, you have been chosen to receive a £800 reward! To claim, call 09061701462. Use the claim code LX392. Valid for 24 hours only.\"\n",
        "\n",
        "# Apply the tokenizer\n",
        "encoding = preprocessing(new_text, tokenizer)\n",
        "print(encoding)\n",
        "# Convert lists to tensors\n",
        "input_ids = torch.tensor(encoding['input_ids'])\n",
        "attention_mask = torch.tensor(encoding['attention_mask'])\n",
        "\n",
        "# Forward pass, calculate logit predictions\n",
        "with torch.no_grad():\n",
        "  output = model(input_ids.to(device), token_type_ids=None, attention_mask=attention_mask.to(device))\n",
        "\n",
        "prediction = 'Spam' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'Ham'\n",
        "\n",
        "print(\"\\n\\nPREDICTION:\")\n",
        "print('Input Text: ', new_text)\n",
        "print('Predicted Class: ', prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etfWnEZWW0p6",
        "outputId": "c17056ce-df9f-4da1-c3e9-17c0680596c6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 23156,   999,  2004,  2256,  8884,  8013,  1010,  2017,  2031,\n",
            "          2042,  4217,  2000,  4374,  1037,  1069, 17914,  2692, 10377,   999,\n",
            "          2000,  4366,  1010,  2655,  5641,  2692,  2575, 16576, 24096, 21472,\n",
            "          2475,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "\n",
            "\n",
            "PREDICTION:\n",
            "Input Text:  Congratulations! As our loyal customer, you have been chosen to receive a £800 reward! To claim, call 09061701462. Use the claim code LX392. Valid for 24 hours only.\n",
            "Predicted Class:  Spam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "<ipython-input-24-12966856353b>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_ids = torch.tensor(encoding['input_ids'])\n",
            "<ipython-input-24-12966856353b>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  attention_mask = torch.tensor(encoding['attention_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUashWQjbRmC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}